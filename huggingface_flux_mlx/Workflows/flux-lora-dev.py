# /// script
# dependencies = []
# 
# [tool.griptape-nodes]
# name = "flux-lora-dev"
# schema_version = "0.6.0"
# engine_version_created_with = "0.42.0"
# node_libraries_referenced = [["HuggingFace Flux MLX Apple Silicon Library", "1.0.0"], ["Griptape Nodes Library", "0.41.0"]]
# is_griptape_provided = false
# is_template = false
# creation_date = 2025-07-23T14:45:34.952443-07:00
# last_modified_date = 2025-07-23T15:39:35.565372-07:00
# 
# ///

import pickle
from griptape.artifacts.image_url_artifact import ImageUrlArtifact
from griptape_nodes.node_library.library_registry import IconVariant, NodeMetadata
from griptape_nodes.retained_mode.events.connection_events import CreateConnectionRequest
from griptape_nodes.retained_mode.events.flow_events import CreateFlowRequest
from griptape_nodes.retained_mode.events.library_events import GetAllInfoForAllLibrariesRequest, GetAllInfoForAllLibrariesResultSuccess
from griptape_nodes.retained_mode.events.node_events import CreateNodeRequest
from griptape_nodes.retained_mode.events.parameter_events import AddParameterToNodeRequest, AlterParameterDetailsRequest, SetParameterValueRequest
from griptape_nodes.retained_mode.griptape_nodes import GriptapeNodes

response = GriptapeNodes.LibraryManager().get_all_info_for_all_libraries_request(GetAllInfoForAllLibrariesRequest())

if isinstance(response, GetAllInfoForAllLibrariesResultSuccess) and len(response.library_name_to_library_info.keys()) < 1:
    GriptapeNodes.LibraryManager().load_all_libraries_from_config()

context_manager = GriptapeNodes.ContextManager()

if not context_manager.has_current_workflow():
    context_manager.push_workflow(workflow_name='flux-lora-dev')

"""
1. We've collated all of the unique parameter values into a dictionary so that we do not have to duplicate them.
   This minimizes the size of the code, especially for large objects like serialized image files.
2. We're using a prefix so that it's clear which Flow these values are associated with.
3. The values are serialized using pickle, which is a binary format. This makes them harder to read, but makes
   them consistently save and load. It allows us to serialize complex objects like custom classes, which otherwise
   would be difficult to serialize.
"""
top_level_unique_values_dict = {'ff8e1df5-87d3-4b29-b54e-ee483ec916e2': pickle.loads(b'\x80\x04\x95 \x00\x00\x00\x00\x00\x00\x00\x8c\x1cblack-forest-labs/FLUX.1-dev\x94.'), '14221786-b9d4-4387-a468-bf1e3692158c': pickle.loads(b'\x80\x04\x95\t\x00\x00\x00\x00\x00\x00\x00\x8c\x054-bit\x94.'), '2ce309fa-1db1-4952-a349-9d4202ee048d': pickle.loads(b'\x80\x04\x95;\x00\x00\x00\x00\x00\x00\x00\x8c7ghibli style, business man in a suit on a city street. \x94.'), '5f544431-a082-4243-8244-1ee0327802ad': pickle.loads(b'\x80\x04\x95:\x00\x00\x00\x00\x00\x00\x00\x8c6ghibli style, business man in a suit on a city street.\x94.'), '62e11438-6b97-4261-b978-5d538b06b044': pickle.loads(b'\x80\x04]\x94.'), '6c55561f-cb05-42e4-9b68-84a7702ca260': pickle.loads(b'\x80\x04\x95\x04\x00\x00\x00\x00\x00\x00\x00M\x00\x04.'), 'b80c8557-3e9a-4542-9df8-78d9093bfb4f': pickle.loads(b'\x80\x04\x95\n\x00\x00\x00\x00\x00\x00\x00G@\x1e\x00\x00\x00\x00\x00\x00.'), '0bcc79f6-fdc5-40ef-8607-70b009c8b4ac': pickle.loads(b'\x80\x04K\x14.'), 'd913a66b-c171-4616-b644-262da76fa75a': pickle.loads(b'\x80\x04\x95\x04\x00\x00\x00\x00\x00\x00\x00M90.'), 'cf288533-ba9b-4f53-80f5-f9898d13c7a1': pickle.loads(b'\x80\x04\x95\x04\x00\x00\x00\x00\x00\x00\x00M:0.'), '14af2b81-fc4f-4dae-a3b7-4aa7df6461e6': pickle.loads(b'\x80\x04\x95\r\x00\x00\x00\x00\x00\x00\x00\x8c\tincrement\x94.'), 'db213e20-fae8-4f5f-a49e-70d9fd96c484': pickle.loads(b'\x80\x04\x95\x1c\x00\x00\x00\x00\x00\x00\x00\x8c\x18None (use model default)\x94.'), '80522997-f0de-496a-9278-bd432a42d54c': pickle.loads(b'\x80\x04\x95\x06\x00\x00\x00\x00\x00\x00\x00]\x94]\x94a.'), '6e69d489-9118-447a-b5c7-39d0cd00dd0c': pickle.loads(b'\x80\x04]\x94.'), '06bac873-b619-4de3-8b47-45f99e38eea9': pickle.loads(b'\x80\x04\x95o\x01\x00\x00\x00\x00\x00\x00\x8c%griptape.artifacts.image_url_artifact\x94\x8c\x10ImageUrlArtifact\x94\x93\x94)\x81\x94}\x94(\x8c\x04type\x94\x8c\x10ImageUrlArtifact\x94\x8c\x0bmodule_name\x94\x8c%griptape.artifacts.image_url_artifact\x94\x8c\x02id\x94\x8c 3251b30d78b74a119f564faa738d3f0c\x94\x8c\treference\x94N\x8c\x04meta\x94}\x94\x8c\x04name\x94h\n\x8c\x16encoding_error_handler\x94\x8c\x06strict\x94\x8c\x08encoding\x94\x8c\x05utf-8\x94\x8c\x05value\x94\x8cRhttp://localhost:8124/static/flux_generation_flux1_dev_seed_12346.png?t=1753305630\x94ub.'), 'a063c1be-97b0-4471-88cd-7535d2607086': pickle.loads(b'\x80\x04\x95\xb3\x02\x00\x00\x00\x00\x00\x00X\xac\x02\x00\x00{\n  "backend": "MLX (Apple Silicon)",\n  "model": "black-forest-labs/FLUX.1-dev",\n  "mflux_model": "dev",\n  "original_prompts": [\n    "ghibli style, business man in a suit on a city street."\n  ],\n  "prompt_count": 1,\n  "combined_prompt": "ghibli style, business man in a suit on a city street.",\n  "enhanced_prompt": "ghibli style, business man in a suit on a city street.",\n  "width": 1024,\n  "height": 1024,\n  "steps": 20,\n  "guidance_scale": 7.5,\n  "seed_original": 12345,\n  "seed_control": "increment",\n  "seed_used": 12346,\n  "quantization": "4-bit",\n  "t5_encoder": "None (use model default)",\n  "clip_encoder": "None (use model default)",\n  "loras_used": [],\n  "lora_count": 0\n}\x94.'), 'a7472640-2a5c-4e33-8f5d-dfebe1ca4453': pickle.loads(b'\x80\x04\x95\x91\x00\x00\x00\x00\x00\x00\x00\x8c\x8d\xe2\x9c\x85 Generation complete!\nBackend: MLX (Apple Silicon)\nModel: FLUX.1 Dev\nPrompt: 1\nQuantization: 4-bit\nSeed: 12346 (increment)\nSize: 1024x1024\x94.'), '0866c02f-b4a4-4e50-8fc4-9dbbddbb5e1c': pickle.loads(b'\x80\x04\x95$\x00\x00\x00\x00\x00\x00\x00]\x94\x8c\x1dThe man is holding a coffee. \x94a.'), '9485fa0e-640a-4ed4-b6a8-de4cc5639869': pickle.loads(b'\x80\x04\x95!\x00\x00\x00\x00\x00\x00\x00\x8c\x1dThe man is holding a coffee. \x94.'), '2accfb67-790a-4942-a6ba-fb0f87449c03': pickle.loads(b"\x80\x04\x95\x95\x01\x00\x00\x00\x00\x00\x00]\x94}\x94(\x8c\x04path\x94\x8c\x1fInstantX/FLUX.1-dev-LoRA-Ghibli\x94\x8c\x05scale\x94G?\xf0\x00\x00\x00\x00\x00\x00\x8c\x04name\x94\x8c\x16FLUX.1-dev-LoRA-Ghibli\x94\x8c\x0bdescription\x94\x8c\x0fFLUX LoRA model\x94\x8c\x04type\x94\x8c\x0bhuggingface\x94\x8c\x05gated\x94\x89\x8c\tdownloads\x94M\x88\x01\x8c\x04tags\x94]\x94(\x8c\tdiffusers\x94\x8c\rtext-to-image\x94\x8c\x10stable-diffusion\x94\x8c\x04lora\x94\x8c\x10image-generation\x94\x8c\x04flux\x94\x8c\x0bsafetensors\x94\x8c\x02en\x94\x8c'base_model:black-forest-labs/FLUX.1-dev\x94\x8c/base_model:adapter:black-forest-labs/FLUX.1-dev\x94\x8c\rlicense:other\x94\x8c\tregion:us\x94eua."), '6e9c85fb-42ef-4274-9cdb-eb62a488980f': pickle.loads(b"\x80\x04\x95\x92\x01\x00\x00\x00\x00\x00\x00}\x94(\x8c\x04path\x94\x8c\x1fInstantX/FLUX.1-dev-LoRA-Ghibli\x94\x8c\x05scale\x94G?\xf0\x00\x00\x00\x00\x00\x00\x8c\x04name\x94\x8c\x16FLUX.1-dev-LoRA-Ghibli\x94\x8c\x0bdescription\x94\x8c\x0fFLUX LoRA model\x94\x8c\x04type\x94\x8c\x0bhuggingface\x94\x8c\x05gated\x94\x89\x8c\tdownloads\x94M\x88\x01\x8c\x04tags\x94]\x94(\x8c\tdiffusers\x94\x8c\rtext-to-image\x94\x8c\x10stable-diffusion\x94\x8c\x04lora\x94\x8c\x10image-generation\x94\x8c\x04flux\x94\x8c\x0bsafetensors\x94\x8c\x02en\x94\x8c'base_model:black-forest-labs/FLUX.1-dev\x94\x8c/base_model:adapter:black-forest-labs/FLUX.1-dev\x94\x8c\rlicense:other\x94\x8c\tregion:us\x94eu."), '77915257-f0f1-423b-b471-cc6b4ff3f129': pickle.loads(b'\x80\x04\x95#\x00\x00\x00\x00\x00\x00\x00\x8c\x1fInstantX/FLUX.1-dev-LoRA-Ghibli\x94.'), '8b64a023-e866-4ff5-92e0-41f1cebcfc57': pickle.loads(b'\x80\x04\x95\n\x00\x00\x00\x00\x00\x00\x00G?\xf0\x00\x00\x00\x00\x00\x00.'), '2da60587-323f-45cc-a65e-a9a77f23b9e4': pickle.loads(b"\x80\x04\x95 \x01\x00\x00\x00\x00\x00\x00X\x19\x01\x00\x00\xe2\x9c\x85 LoRA Selected: FLUX.1-dev-LoRA-Ghibli\n\xf0\x9f\x93\x81 Repository: InstantX/FLUX.1-dev-LoRA-Ghibli\n\xe2\x9a\x96\xef\xb8\x8f Scale: 1.0\n\xf0\x9f\x93\x9d Description: FLUX LoRA model\n\xf0\x9f\x93\x88 Downloads: 392\n\xf0\x9f\x8f\xb7\xef\xb8\x8f Tags: text-to-image, stable-diffusion, lora, image-generation\n\n\xf0\x9f\x92\xa1 Connect to FLUX node's LoRA parameter list\x94."), '92ba8134-af28-43f1-b244-8e68721b4868': pickle.loads(b'\x80\x04\x95E\x00\x00\x00\x00\x00\x00\x00]\x94(\x8c\x1dThe man is holding a coffee. \x94\x8c\x1dThe man is wearing a Fedora. \x94e.'), '718432d6-35e1-4f73-a868-d6b20806148b': pickle.loads(b'\x80\x04\x95!\x00\x00\x00\x00\x00\x00\x00\x8c\x1dThe man is wearing a Fedora. \x94.'), 'abd20ee0-7094-4f7d-99e0-4b0057c02bb9': pickle.loads(b'\x80\x04K\x0f.'), 'a43357b4-51b5-453d-87aa-d4c972ee9533': pickle.loads(b'\x80\x04\x95\x04\x00\x00\x00\x00\x00\x00\x00M=0.'), '482b89e0-0aa1-4a3a-9fd4-3fef46c74ce6': pickle.loads(b"\x80\x04\x95\x95\x01\x00\x00\x00\x00\x00\x00]\x94}\x94(\x8c\x04path\x94\x8c\x1fInstantX/FLUX.1-dev-LoRA-Ghibli\x94\x8c\x05scale\x94G?\xf0\x00\x00\x00\x00\x00\x00\x8c\x04name\x94\x8c\x16FLUX.1-dev-LoRA-Ghibli\x94\x8c\x0bdescription\x94\x8c\x0fFLUX LoRA model\x94\x8c\x04type\x94\x8c\x0bhuggingface\x94\x8c\x05gated\x94\x89\x8c\tdownloads\x94M\x88\x01\x8c\x04tags\x94]\x94(\x8c\tdiffusers\x94\x8c\rtext-to-image\x94\x8c\x10stable-diffusion\x94\x8c\x04lora\x94\x8c\x10image-generation\x94\x8c\x04flux\x94\x8c\x0bsafetensors\x94\x8c\x02en\x94\x8c'base_model:black-forest-labs/FLUX.1-dev\x94\x8c/base_model:adapter:black-forest-labs/FLUX.1-dev\x94\x8c\rlicense:other\x94\x8c\tregion:us\x94eua."), '7e9580e7-226f-4882-aa33-2d63a39b37e8': pickle.loads(b'\x80\x04\x95!\x00\x00\x00\x00\x00\x00\x00\x8c\x1dThe man is wearing a fedora. \x94.')}

'# Create the Flow, then do work within it as context.'

flow0_name = GriptapeNodes.handle_request(CreateFlowRequest(parent_flow_name=None, set_as_new_context=False, metadata={})).flow_name

with GriptapeNodes.ContextManager().flow(flow0_name):
    node0_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='FluxInference', specific_library_name='HuggingFace Flux MLX Apple Silicon Library', node_name='Flux MLX Inference', metadata={'position': {'x': 203.70264317180613, 'y': 334.0837004405286}, 'tempId': 'placing-1753305026739-609puh', 'library_node_metadata': NodeMetadata(category='MLX', description='FLUX inference optimized for Apple Silicon M1/M2/M3 chips using MLX framework. Provides native acceleration with 4-bit quantization.', display_name='Flux MLX Inference', tags=None, icon='Image', color=None, group=None), 'library': 'HuggingFace Flux MLX Apple Silicon Library', 'node_type': 'FluxInference', 'category': 'MLX', 'size': {'width': 440, 'height': 1230}}, resolution='resolved', initial_setup=True)).node_name
    with GriptapeNodes.ContextManager().node(node0_name):
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='additional_prompts', default_value=[], tooltip='Optional additional prompts to combine with main prompt.\nConnect multiple prompt sources or manually add prompts.', initial_setup=True))
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='steps', tooltip='Number of inference steps. FLUX.1-dev works best with 15-50 steps (higher quality). Enter any integer value.', initial_setup=True))
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='loras', default_value=[], tooltip="Connect LoRA objects from HuggingFace LoRA Discovery nodes.\nEach LoRA dict should contain 'path' and 'scale' keys.\nMultiple LoRAs will be applied in sequence.", initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='loras_ParameterListUniqueParamID_02b032d8d3e146f1bdfea0f07f1e118e', default_value=[], tooltip="Connect LoRA objects from HuggingFace LoRA Discovery nodes.\nEach LoRA dict should contain 'path' and 'scale' keys.\nMultiple LoRAs will be applied in sequence.", type='dict', input_types=['dict', 'list[dict]'], output_type='dict', ui_options={'display_name': 'LoRA Models'}, mode_allowed_input=True, mode_allowed_property=False, mode_allowed_output=False, parent_container_name='loras', initial_setup=True))
    node1_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='FluxInference', specific_library_name='HuggingFace Flux MLX Apple Silicon Library', node_name='Flux MLX Inference_1', metadata={'position': {'x': 1471.2090034816258, 'y': 167.89775285039022}, 'tempId': 'placing-1753305026739-609puh', 'library_node_metadata': {'category': 'MLX', 'description': 'FLUX inference optimized for Apple Silicon M1/M2/M3 chips using MLX framework. Provides native acceleration with 4-bit quantization.'}, 'library': 'HuggingFace Flux MLX Apple Silicon Library', 'node_type': 'FluxInference', 'category': 'MLX', 'size': {'width': 556, 'height': 1582}}, initial_setup=True)).node_name
    with GriptapeNodes.ContextManager().node(node1_name):
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='additional_prompts', default_value=[], tooltip='Optional additional prompts to combine with main prompt.\nConnect multiple prompt sources or manually add prompts.', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='additional_prompts_ParameterListUniqueParamID_1916914540d54ee5af41c21a74d75c4f', default_value=[], tooltip='Optional additional prompts to combine with main prompt.\nConnect multiple prompt sources or manually add prompts.', type='str', input_types=['str', 'list[str]'], output_type='str', ui_options={'display_name': 'Additional Prompts'}, mode_allowed_input=True, mode_allowed_property=False, mode_allowed_output=False, parent_container_name='additional_prompts', initial_setup=True))
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='steps', tooltip='Number of inference steps. FLUX.1-dev works best with 15-50 steps (higher quality). Enter any integer value.', initial_setup=True))
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='loras', default_value=[], tooltip="Connect LoRA objects from HuggingFace LoRA Discovery nodes.\nEach LoRA dict should contain 'path' and 'scale' keys.\nMultiple LoRAs will be applied in sequence.", initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='loras_ParameterListUniqueParamID_645214e9cb244c1dbfd9dcf35d929e65', default_value=[], tooltip="Connect LoRA objects from HuggingFace LoRA Discovery nodes.\nEach LoRA dict should contain 'path' and 'scale' keys.\nMultiple LoRAs will be applied in sequence.", type='dict', input_types=['dict', 'list[dict]'], output_type='dict', ui_options={'display_name': 'LoRA Models'}, mode_allowed_input=True, mode_allowed_property=False, mode_allowed_output=False, parent_container_name='loras', initial_setup=True))
    node2_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='HuggingFaceLoRADiscovery', specific_library_name='HuggingFace Flux MLX Apple Silicon Library', node_name='HuggingFace LoRA Discovery', metadata={'position': {'x': 860.0176211453745, 'y': -51.22099853157114}, 'tempId': 'placing-1753305194231-3n0eq', 'library_node_metadata': NodeMetadata(category='MLX', description='Discover and select FLUX LoRA models from your HuggingFace cache with metadata and scale control.', display_name='HuggingFace LoRA Discovery', tags=None, icon='Search', color=None, group=None), 'library': 'HuggingFace Flux MLX Apple Silicon Library', 'node_type': 'HuggingFaceLoRADiscovery', 'category': 'MLX'}, resolution='resolved', initial_setup=True)).node_name
    node3_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='FluxInference', specific_library_name='HuggingFace Flux MLX Apple Silicon Library', node_name='Flux MLX Inference_2', metadata={'position': {'x': 2219.8021767990867, 'y': 232.67603343626047}, 'tempId': 'placing-1753305026739-609puh', 'library_node_metadata': {'category': 'MLX', 'description': 'FLUX inference optimized for Apple Silicon M1/M2/M3 chips using MLX framework. Provides native acceleration with 4-bit quantization.'}, 'library': 'HuggingFace Flux MLX Apple Silicon Library', 'node_type': 'FluxInference', 'category': 'MLX', 'size': {'width': 556, 'height': 1622}}, initial_setup=True)).node_name
    with GriptapeNodes.ContextManager().node(node3_name):
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='additional_prompts', default_value=[], tooltip='Optional additional prompts to combine with main prompt.\nConnect multiple prompt sources or manually add prompts.', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='additional_prompts_ParameterListUniqueParamID_5b2edc2b16554742a975b4bde75f1672', default_value=[], tooltip='Optional additional prompts to combine with main prompt.\nConnect multiple prompt sources or manually add prompts.', type='str', input_types=['str', 'list[str]'], output_type='str', ui_options={'display_name': 'Additional Prompts'}, mode_allowed_input=True, mode_allowed_property=False, mode_allowed_output=False, parent_container_name='additional_prompts', initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='additional_prompts_ParameterListUniqueParamID_b060e72af5ed4ab6b6616c1931ecc825', default_value=[], tooltip='Optional additional prompts to combine with main prompt.\nConnect multiple prompt sources or manually add prompts.', type='str', input_types=['str', 'list[str]'], output_type='str', ui_options={'display_name': 'Additional Prompts'}, mode_allowed_input=True, mode_allowed_property=False, mode_allowed_output=False, parent_container_name='additional_prompts', initial_setup=True))
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='steps', tooltip='Number of inference steps. FLUX.1-dev works best with 15-50 steps (higher quality). Enter any integer value.', initial_setup=True))
        GriptapeNodes.handle_request(AlterParameterDetailsRequest(parameter_name='loras', default_value=[], tooltip="Connect LoRA objects from HuggingFace LoRA Discovery nodes.\nEach LoRA dict should contain 'path' and 'scale' keys.\nMultiple LoRAs will be applied in sequence.", initial_setup=True))
        GriptapeNodes.handle_request(AddParameterToNodeRequest(parameter_name='loras_ParameterListUniqueParamID_65703aaed3cb4e27996df3a9388934f6', default_value=[], tooltip="Connect LoRA objects from HuggingFace LoRA Discovery nodes.\nEach LoRA dict should contain 'path' and 'scale' keys.\nMultiple LoRAs will be applied in sequence.", type='dict', input_types=['dict', 'list[dict]'], output_type='dict', ui_options={'display_name': 'LoRA Models'}, mode_allowed_input=True, mode_allowed_property=False, mode_allowed_output=False, parent_container_name='loras', initial_setup=True))
    node4_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='DisplayText', specific_library_name='Griptape Nodes Library', node_name='Display Text', metadata={'position': {'x': 952.5990845498677, 'y': 656.753401939746}, 'tempId': 'placing-1753305465004-uyv3fp', 'library_node_metadata': NodeMetadata(category='text', description='DisplayText node', display_name='Display Text', tags=None, icon=None, color=None, group='general'), 'library': 'Griptape Nodes Library', 'node_type': 'DisplayText', 'category': 'text'}, resolution='resolved', initial_setup=True)).node_name
    node5_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='DisplayText', specific_library_name='Griptape Nodes Library', node_name='Display Text_1', metadata={'position': {'x': 958.0813210048318, 'y': 882.693393631293}, 'tempId': 'placing-1753305465004-uyv3fp', 'library_node_metadata': NodeMetadata(category='text', description='DisplayText node', display_name='Display Text', tags=None, icon=None, color=None, group='general'), 'library': 'Griptape Nodes Library', 'node_type': 'DisplayText', 'category': 'text'}, resolution='resolved', initial_setup=True)).node_name
    node6_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='DisplayText', specific_library_name='Griptape Nodes Library', node_name='Display Text_2', metadata={'position': {'x': 882.5735092988966, 'y': 610.9335190994808}, 'tempId': 'placing-1753310293256-wbcpjm', 'library_node_metadata': {'category': 'text', 'description': 'DisplayText node'}, 'library': 'Griptape Nodes Library', 'node_type': 'DisplayText', 'category': 'text', 'size': {'width': 400, 'height': 166}}, initial_setup=True)).node_name
    node7_name = GriptapeNodes.handle_request(CreateNodeRequest(node_type='DisplayText', specific_library_name='Griptape Nodes Library', node_name='Display Text_3', metadata={'position': {'x': 883.7169653553569, 'y': 811.2362432988648}, 'tempId': 'placing-1753310293256-wbcpjm', 'library_node_metadata': {'category': 'text', 'description': 'DisplayText node'}, 'library': 'Griptape Nodes Library', 'node_type': 'DisplayText', 'category': 'text', 'size': {'width': 400, 'height': 166}}, initial_setup=True)).node_name
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node0_name, source_parameter_name='seed', target_node_name=node1_name, target_parameter_name='seed', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node2_name, source_parameter_name='lora_dict', target_node_name=node1_name, target_parameter_name='loras_ParameterListUniqueParamID_645214e9cb244c1dbfd9dcf35d929e65', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node2_name, source_parameter_name='lora_dict', target_node_name=node3_name, target_parameter_name='loras_ParameterListUniqueParamID_65703aaed3cb4e27996df3a9388934f6', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node1_name, source_parameter_name='seed', target_node_name=node3_name, target_parameter_name='seed', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node0_name, source_parameter_name='exec_out', target_node_name=node1_name, target_parameter_name='exec_in', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node1_name, source_parameter_name='exec_out', target_node_name=node3_name, target_parameter_name='exec_in', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node6_name, source_parameter_name='text', target_node_name=node1_name, target_parameter_name='additional_prompts_ParameterListUniqueParamID_1916914540d54ee5af41c21a74d75c4f', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node6_name, source_parameter_name='text', target_node_name=node3_name, target_parameter_name='additional_prompts_ParameterListUniqueParamID_5b2edc2b16554742a975b4bde75f1672', initial_setup=True))
    GriptapeNodes.handle_request(CreateConnectionRequest(source_node_name=node7_name, source_parameter_name='text', target_node_name=node3_name, target_parameter_name='additional_prompts_ParameterListUniqueParamID_b060e72af5ed4ab6b6616c1931ecc825', initial_setup=True))
    with GriptapeNodes.ContextManager().node(node0_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='model', node_name=node0_name, value=top_level_unique_values_dict['ff8e1df5-87d3-4b29-b54e-ee483ec916e2'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='quantization', node_name=node0_name, value=top_level_unique_values_dict['14221786-b9d4-4387-a468-bf1e3692158c'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='main_prompt', node_name=node0_name, value=top_level_unique_values_dict['2ce309fa-1db1-4952-a349-9d4202ee048d'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='main_prompt', node_name=node0_name, value=top_level_unique_values_dict['5f544431-a082-4243-8244-1ee0327802ad'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='additional_prompts', node_name=node0_name, value=top_level_unique_values_dict['62e11438-6b97-4261-b978-5d538b06b044'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='width', node_name=node0_name, value=top_level_unique_values_dict['6c55561f-cb05-42e4-9b68-84a7702ca260'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='width', node_name=node0_name, value=top_level_unique_values_dict['6c55561f-cb05-42e4-9b68-84a7702ca260'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='height', node_name=node0_name, value=top_level_unique_values_dict['6c55561f-cb05-42e4-9b68-84a7702ca260'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='height', node_name=node0_name, value=top_level_unique_values_dict['6c55561f-cb05-42e4-9b68-84a7702ca260'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='guidance_scale', node_name=node0_name, value=top_level_unique_values_dict['b80c8557-3e9a-4542-9df8-78d9093bfb4f'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='steps', node_name=node0_name, value=top_level_unique_values_dict['0bcc79f6-fdc5-40ef-8607-70b009c8b4ac'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='seed', node_name=node0_name, value=top_level_unique_values_dict['d913a66b-c171-4616-b644-262da76fa75a'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='seed', node_name=node0_name, value=top_level_unique_values_dict['cf288533-ba9b-4f53-80f5-f9898d13c7a1'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='seed_control', node_name=node0_name, value=top_level_unique_values_dict['14af2b81-fc4f-4dae-a3b7-4aa7df6461e6'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='t5_encoder', node_name=node0_name, value=top_level_unique_values_dict['db213e20-fae8-4f5f-a49e-70d9fd96c484'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='clip_encoder', node_name=node0_name, value=top_level_unique_values_dict['db213e20-fae8-4f5f-a49e-70d9fd96c484'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='loras', node_name=node0_name, value=top_level_unique_values_dict['80522997-f0de-496a-9278-bd432a42d54c'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='loras_ParameterListUniqueParamID_02b032d8d3e146f1bdfea0f07f1e118e', node_name=node0_name, value=top_level_unique_values_dict['6e69d489-9118-447a-b5c7-39d0cd00dd0c'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='image', node_name=node0_name, value=top_level_unique_values_dict['06bac873-b619-4de3-8b47-45f99e38eea9'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='generation_info', node_name=node0_name, value=top_level_unique_values_dict['a063c1be-97b0-4471-88cd-7535d2607086'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='status', node_name=node0_name, value=top_level_unique_values_dict['a7472640-2a5c-4e33-8f5d-dfebe1ca4453'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='actual_seed', node_name=node0_name, value=top_level_unique_values_dict['cf288533-ba9b-4f53-80f5-f9898d13c7a1'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node1_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='model', node_name=node1_name, value=top_level_unique_values_dict['ff8e1df5-87d3-4b29-b54e-ee483ec916e2'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='quantization', node_name=node1_name, value=top_level_unique_values_dict['14221786-b9d4-4387-a468-bf1e3692158c'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='main_prompt', node_name=node1_name, value=top_level_unique_values_dict['2ce309fa-1db1-4952-a349-9d4202ee048d'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='additional_prompts', node_name=node1_name, value=top_level_unique_values_dict['0866c02f-b4a4-4e50-8fc4-9dbbddbb5e1c'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='additional_prompts_ParameterListUniqueParamID_1916914540d54ee5af41c21a74d75c4f', node_name=node1_name, value=top_level_unique_values_dict['9485fa0e-640a-4ed4-b6a8-de4cc5639869'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='width', node_name=node1_name, value=top_level_unique_values_dict['6c55561f-cb05-42e4-9b68-84a7702ca260'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='height', node_name=node1_name, value=top_level_unique_values_dict['6c55561f-cb05-42e4-9b68-84a7702ca260'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='guidance_scale', node_name=node1_name, value=top_level_unique_values_dict['b80c8557-3e9a-4542-9df8-78d9093bfb4f'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='steps', node_name=node1_name, value=top_level_unique_values_dict['0bcc79f6-fdc5-40ef-8607-70b009c8b4ac'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='seed', node_name=node1_name, value=top_level_unique_values_dict['cf288533-ba9b-4f53-80f5-f9898d13c7a1'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='seed_control', node_name=node1_name, value=top_level_unique_values_dict['14af2b81-fc4f-4dae-a3b7-4aa7df6461e6'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='t5_encoder', node_name=node1_name, value=top_level_unique_values_dict['db213e20-fae8-4f5f-a49e-70d9fd96c484'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='clip_encoder', node_name=node1_name, value=top_level_unique_values_dict['db213e20-fae8-4f5f-a49e-70d9fd96c484'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='loras', node_name=node1_name, value=top_level_unique_values_dict['2accfb67-790a-4942-a6ba-fb0f87449c03'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='loras_ParameterListUniqueParamID_645214e9cb244c1dbfd9dcf35d929e65', node_name=node1_name, value=top_level_unique_values_dict['6e9c85fb-42ef-4274-9cdb-eb62a488980f'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node2_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='selected_lora', node_name=node2_name, value=top_level_unique_values_dict['77915257-f0f1-423b-b471-cc6b4ff3f129'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='lora_scale', node_name=node2_name, value=top_level_unique_values_dict['8b64a023-e866-4ff5-92e0-41f1cebcfc57'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='lora_dict', node_name=node2_name, value=top_level_unique_values_dict['6e9c85fb-42ef-4274-9cdb-eb62a488980f'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='lora_path', node_name=node2_name, value=top_level_unique_values_dict['77915257-f0f1-423b-b471-cc6b4ff3f129'], initial_setup=True, is_output=True))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='status', node_name=node2_name, value=top_level_unique_values_dict['2da60587-323f-45cc-a65e-a9a77f23b9e4'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node3_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='model', node_name=node3_name, value=top_level_unique_values_dict['ff8e1df5-87d3-4b29-b54e-ee483ec916e2'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='quantization', node_name=node3_name, value=top_level_unique_values_dict['14221786-b9d4-4387-a468-bf1e3692158c'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='main_prompt', node_name=node3_name, value=top_level_unique_values_dict['2ce309fa-1db1-4952-a349-9d4202ee048d'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='additional_prompts', node_name=node3_name, value=top_level_unique_values_dict['92ba8134-af28-43f1-b244-8e68721b4868'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='additional_prompts_ParameterListUniqueParamID_5b2edc2b16554742a975b4bde75f1672', node_name=node3_name, value=top_level_unique_values_dict['9485fa0e-640a-4ed4-b6a8-de4cc5639869'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='additional_prompts_ParameterListUniqueParamID_b060e72af5ed4ab6b6616c1931ecc825', node_name=node3_name, value=top_level_unique_values_dict['718432d6-35e1-4f73-a868-d6b20806148b'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='width', node_name=node3_name, value=top_level_unique_values_dict['6c55561f-cb05-42e4-9b68-84a7702ca260'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='height', node_name=node3_name, value=top_level_unique_values_dict['6c55561f-cb05-42e4-9b68-84a7702ca260'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='guidance_scale', node_name=node3_name, value=top_level_unique_values_dict['b80c8557-3e9a-4542-9df8-78d9093bfb4f'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='steps', node_name=node3_name, value=top_level_unique_values_dict['abd20ee0-7094-4f7d-99e0-4b0057c02bb9'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='seed', node_name=node3_name, value=top_level_unique_values_dict['a43357b4-51b5-453d-87aa-d4c972ee9533'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='seed_control', node_name=node3_name, value=top_level_unique_values_dict['14af2b81-fc4f-4dae-a3b7-4aa7df6461e6'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='t5_encoder', node_name=node3_name, value=top_level_unique_values_dict['db213e20-fae8-4f5f-a49e-70d9fd96c484'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='clip_encoder', node_name=node3_name, value=top_level_unique_values_dict['db213e20-fae8-4f5f-a49e-70d9fd96c484'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='loras', node_name=node3_name, value=top_level_unique_values_dict['482b89e0-0aa1-4a3a-9fd4-3fef46c74ce6'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='loras_ParameterListUniqueParamID_65703aaed3cb4e27996df3a9388934f6', node_name=node3_name, value=top_level_unique_values_dict['6e9c85fb-42ef-4274-9cdb-eb62a488980f'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node4_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='text', node_name=node4_name, value=top_level_unique_values_dict['9485fa0e-640a-4ed4-b6a8-de4cc5639869'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='text', node_name=node4_name, value=top_level_unique_values_dict['9485fa0e-640a-4ed4-b6a8-de4cc5639869'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node5_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='text', node_name=node5_name, value=top_level_unique_values_dict['7e9580e7-226f-4882-aa33-2d63a39b37e8'], initial_setup=True, is_output=False))
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='text', node_name=node5_name, value=top_level_unique_values_dict['7e9580e7-226f-4882-aa33-2d63a39b37e8'], initial_setup=True, is_output=True))
    with GriptapeNodes.ContextManager().node(node6_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='text', node_name=node6_name, value=top_level_unique_values_dict['9485fa0e-640a-4ed4-b6a8-de4cc5639869'], initial_setup=True, is_output=False))
    with GriptapeNodes.ContextManager().node(node7_name):
        GriptapeNodes.handle_request(SetParameterValueRequest(parameter_name='text', node_name=node7_name, value=top_level_unique_values_dict['718432d6-35e1-4f73-a868-d6b20806148b'], initial_setup=True, is_output=False))
